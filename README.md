# ðŸ’¬ Gemma Chat Agent

Gemma Chat Agent is an **AI-powered conversational assistant** built on top of the **LangChain framework** and deployed through a **Gradio web interface**.  
It integrates the **Gemma model via Ollama** as its core large language model (LLM), while extending its intelligence with practical tools like:

- ðŸ” **DuckDuckGo Search** â†’ fetches the latest web information in real-time.  
- ðŸ“– **Wikipedia Lookup** â†’ provides factual, structured knowledge from Wikipedia.  
- âž— **Calculator** â†’ evaluates math expressions on the fly.  

Unlike a basic chatbot, this agent can **combine reasoning with external tools**, making it capable of answering both conversational queries (â€œWho is Ada Lovelace?â€) and dynamic ones (â€œWhat is 23*89?â€ or â€œWhatâ€™s trending in AI news?â€).  

## âœ¨ Features
- AgentType: **OPENAI_FUNCTIONS** for reliable tool-calling
- Tools: DuckDuckGo search, Wikipedia, Calculator
- Simple memory (chat history)
- Gradio UI (`ChatInterface`) with browser auto-open

The system is built with:
- **LangChain Agents** (using `AgentType.OPENAI_FUNCTIONS`) to seamlessly decide when to call which tool.  
- **Custom memory handling** to keep track of ongoing conversations.  
- **Gradioâ€™s ChatInterface**, offering a clean browser-based UI that launches instantly.  

This makes it an ideal **starter project** for experimenting with:
- ðŸ¤– Tool-augmented LLM agents  
- ðŸ§± Building LangChain applications  
- ðŸŒ Local inference with Ollama + Gemma  
- ðŸŽ¨ Deploying quick ML apps with Gradio  

> Think of it as a lightweight research assistant: it can talk, look things up, calculate, and explain â€” all in one chat window.

## ðŸš€ Quickstart

### 1) Requirements
- Python 3.9+
- [Ollama](https://ollama.ai) installed locally
- Gemma model downloaded:
  ```bash
  ollama pull gemma
